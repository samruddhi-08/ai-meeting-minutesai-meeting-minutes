
# ğŸ¤– AI Meeting Minutes Generator & Action Tracker

Automatically transcribe, summarize, and extract action items from meeting audio, video, or transcripts using GPT-4, Whisper, and LangChain.

---

## ğŸš€ Demo

Upload an `.mp3`, `.mp4`, or `.txt` transcript and get:
- ğŸ§  GPT-4-generated summary
- ğŸ“Œ Action items, decisions, and open points
- â“ Ask context-aware questions using RAG
- ğŸ“¤ Downloadable output (PDF export coming soon)

---

## ğŸ› ï¸ Tech Stack

| Tool          | Purpose                              |
|---------------|--------------------------------------|
| Python        | Backend logic                        |
| Streamlit     | Frontend UI                          |
| OpenAI GPT-4  | Summarization & Q&A                  |
| Whisper       | Speech-to-text transcription         |
| LangChain     | RAG pipeline + prompt orchestration  |
| FAISS         | Vector DB for semantic retrieval     |
| PyMuPDF       | (Optional) PDF output generation     |
| Docker        | Containerized deployment             |

---

## ğŸ“¦ Features

- ğŸ™ï¸ **Upload audio/video/text** meeting files
- ğŸ”Š **Transcribe with Whisper** (offline support)
- ğŸ§  **Summarize** meetings with GPT-4:
  - TL;DR
  - Action Items (Who, What, By When)
  - Decisions
  - Unresolved Questions
- ğŸ” **Ask custom questions** (RAG search)
- ğŸ“„ View all results in a simple **Streamlit dashboard**
- ğŸ’¡ Built for real-world use in **corporate/business meetings**

---

## ğŸ’» Setup Instructions

### 1. Clone this repo

```bash
git clone https://github.com/samruddhi-08/ai-meeting-minutes.git
cd ai-meeting-minutes
```

### 2. Create and activate virtual environment (Python 3.10+)

```bash
python -m venv venv
venv\Scripts\activate   # On Windows
```

### 3. Install requirements

```bash
pip install -r requirements.txt
pip install git+https://github.com/openai/whisper.git
pip install -U langchain-community
```

### 4. Set OpenAI API key

Create a `.env` file in the root:

```
OPENAI_API_KEY=your-api-key-here
```

Or set in terminal:

```bash
$env:OPENAI_API_KEY="your-api-key-here"
```

### 5. Add FFmpeg (for Whisper)

- Download FFmpeg: https://www.gyan.dev/ffmpeg/builds/
- Extract to: `C:\ffmpeg\bin`
- Add `C:\ffmpeg\bin` to your system `PATH`
- Restart your terminal
- Test with: `ffmpeg -version`

---

## ğŸ§ª Run the App

```bash
streamlit run app/ui_app.py
```

Open your browser to [http://localhost:8501](http://localhost:8501)

---

## ğŸ“ Project Structure

```
ai-meeting-minutes/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui_app.py            # Streamlit frontend
â”‚   â”œâ”€â”€ transcribe.py        # Whisper transcription
â”‚   â”œâ”€â”€ summarizer.py        # GPT-4 summarizer
â”‚   â”œâ”€â”€ chunking.py          # Text chunk splitter
â”‚   â”œâ”€â”€ embedding.py         # FAISS vector DB creation
â”‚   â”œâ”€â”€ qa_rag.py            # RAG-based Q&A
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/             # Audio/video/text files
â”œâ”€â”€ models/
â”‚   â””â”€â”€ faiss_index/         # Stored FAISS vector DB
â”œâ”€â”€ .env                     # API keys
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```
